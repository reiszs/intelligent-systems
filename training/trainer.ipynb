{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impossible-shirt",
   "metadata": {},
   "source": [
    "# Table of Contents: <a class=\"anchor\" id=\"toc\"></a>\n",
    "* [Training Pipeline](#pipeline)\n",
    " * [Data extraction](#data-extraction)\n",
    " * [Data formatting](#data-formatting)\n",
    " * [Modeling and Validation](#modelling)\n",
    " * [Model exportation](#model-exportation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-ethernet",
   "metadata": {},
   "source": [
    "# Training Pipeline <a class=\"anchor\" id=\"pipeline\"></a> [↑](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "identified-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-discount",
   "metadata": {},
   "source": [
    "### Data extraction <a class=\"anchor\" id=\"data-extraction\"></a> [↑](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "environmental-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.environ['DATASET_PATH']\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-ability",
   "metadata": {},
   "source": [
    "### Data formatting <a class=\"anchor\" id=\"data-formatting\"></a> [↑](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "after-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatenateTextColumns(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.fillna('')\n",
    "        X = X.agg(' '.join, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "emotional-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"ConcatenateTextColumns\", ConcatenateTextColumns()),\n",
    "        (\"CountVectorizer\", CountVectorizer(max_features=200)),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "later-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = ['query', 'concatenated_tags']\n",
    "X = pipe.fit_transform(df[text_columns])\n",
    "y = df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-level",
   "metadata": {},
   "source": [
    "### Modeling and Validation <a class=\"anchor\" id=\"modelling\"></a> [↑](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "seven-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_validation(X, y, model, n_splits=5, n_repeats=5):\n",
    "    \n",
    "    rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=20)\n",
    "    \n",
    "    # training loop\n",
    "    train_precisions = np.array([])\n",
    "    train_recalls = np.array([])\n",
    "    train_f1_scores = np.array([])\n",
    "    val_precisions = np.array([])\n",
    "    val_recalls = np.array([])\n",
    "    val_f1_scores = np.array([])\n",
    "    for train, val in rkf.split(X, y):\n",
    "        \n",
    "        # model training\n",
    "        model.fit(X[train], y[train])\n",
    "        \n",
    "        # model prediction probabilities\n",
    "        train_preds = model.predict(X[train])\n",
    "        val_preds = model.predict(X[val])\n",
    "        \n",
    "        ### test macro\n",
    "        train_precisions = np.append(train_precisions, precision_score(train_preds, y[train], average='macro'))\n",
    "        train_recalls = np.append(train_recalls, recall_score(train_preds, y[train], average='macro'))\n",
    "        train_f1_scores = np.append(train_f1_scores, f1_score(train_preds, y[train], average='macro'))\n",
    "        val_precisions = np.append(val_precisions, precision_score(val_preds, y[val], average='macro'))\n",
    "        val_recalls = np.append(val_recalls, recall_score(val_preds, y[val], average='macro'))\n",
    "        val_f1_scores = np.append(val_f1_scores, f1_score(val_preds, y[val], average='macro'))\n",
    "        \n",
    "    report = {\n",
    "        'train_precision': {'mean': np.mean(train_precisions), 'std': np.std(train_precisions)},\n",
    "        'train_recall': {'mean': np.mean(train_recalls), 'std': np.std(train_recalls)},\n",
    "        'train_f1_score': {'mean': np.mean(train_f1_scores), 'std': np.std(train_f1_scores)},\n",
    "        'val_precision': {'mean': np.mean(val_precisions), 'std': np.std(val_precisions)},\n",
    "        'val_recall': {'mean': np.mean(val_recalls), 'std': np.std(val_recalls)},\n",
    "        'val_f1_score': {'mean': np.mean(val_f1_scores), 'std': np.std(val_f1_scores)},\n",
    "    }\n",
    "    \n",
    "    return report, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rising-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "report, model = model_validation(X, y, RandomForestClassifier(), n_repeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "medical-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = os.environ['METRICS_PATH']\n",
    "with open(metrics_path, 'w') as file:\n",
    "     file.write(json.dumps(report))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-tiger",
   "metadata": {},
   "source": [
    "### Model exportation <a class=\"anchor\" id=\"model-exportation\"></a> [↑](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "indian-turkish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.environ['MODEL_PATH']\n",
    "joblib.dump(model, model_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
